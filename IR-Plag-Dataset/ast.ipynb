{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa93fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Extrayendo características AST...\n",
      "\n",
      "Distribución del dataset:\n",
      "- Total: 467 archivos\n",
      "- Train: 274 archivos (4 casos)\n",
      "- Test: 193 archivos (3 casos)\n",
      "\n",
      "Entrenando vectorizador...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 148\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# Preparamos los vectores para los originales de train\u001b[39;00m\n\u001b[32m    146\u001b[39m train_originals = train_df[train_df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m'\u001b[39m].set_index(\u001b[33m'\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    147\u001b[39m train_original_vectors = {\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     case_id: vectorizer.transform([\u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mast_tokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, case_id \u001b[38;5;129;01min\u001b[39;00m train_originals.reset_index()[[\u001b[33m'\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m'\u001b[39m]].itertuples(index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    150\u001b[39m }\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m## 5. Evaluación del Modelo\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_model\u001b[39m(vectors, df, original_vectors, threshold=\u001b[32m0.7\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1183\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1181\u001b[39m     key = \u001b[38;5;28mtuple\u001b[39m(com.apply_if_callable(x, \u001b[38;5;28mself\u001b[39m.obj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m-> \u001b[39m\u001b[32m1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_tuple(key)\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4221\u001b[39m, in \u001b[36mDataFrame._get_value\u001b[39m\u001b[34m(self, index, col, takeable)\u001b[39m\n\u001b[32m   4215\u001b[39m engine = \u001b[38;5;28mself\u001b[39m.index._engine\n\u001b[32m   4217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, MultiIndex):\n\u001b[32m   4218\u001b[39m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[32m   4219\u001b[39m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[32m   4220\u001b[39m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4221\u001b[39m     row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m series._values[row]\n\u001b[32m   4224\u001b[39m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[32m   4225\u001b[39m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import javalang\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_dir = \"C:/Users/adria/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/AppAvanzadas/IR-Plag-Dataset/IR-Plag-Dataset\"\n",
    "\n",
    "## 1. Carga y Preprocesamiento del Dataset\n",
    "def load_dataset(base_dir):\n",
    "    data = []\n",
    "    \n",
    "    for case_id in os.listdir(base_dir):\n",
    "        case_path = os.path.join(base_dir, case_id)\n",
    "        if not os.path.isdir(case_path):\n",
    "            continue\n",
    "\n",
    "        # Archivos originales\n",
    "        original_path = os.path.join(case_path, \"original\")\n",
    "        if os.path.exists(original_path):\n",
    "            for file in os.listdir(original_path):\n",
    "                if file.endswith(\".java\"):\n",
    "                    data.append({\n",
    "                        \"case_id\": case_id,\n",
    "                        \"file_path\": os.path.join(original_path, file),\n",
    "                        \"label\": \"original\"\n",
    "                    })\n",
    "\n",
    "        # Archivos no plagiados\n",
    "        non_plag_path = os.path.join(case_path, \"non-plagiarized\")\n",
    "        if os.path.exists(non_plag_path):\n",
    "            for author in os.listdir(non_plag_path):\n",
    "                author_path = os.path.join(non_plag_path, author)\n",
    "                if os.path.isdir(author_path):\n",
    "                    for file in os.listdir(author_path):\n",
    "                        if file.endswith(\".java\"):\n",
    "                            data.append({\n",
    "                                \"case_id\": case_id,\n",
    "                                \"file_path\": os.path.join(author_path, file),\n",
    "                                \"label\": \"non-plagiarized\"\n",
    "                            })\n",
    "\n",
    "        # Archivos plagiados\n",
    "        plag_path = os.path.join(case_path, \"plagiarized\")\n",
    "        if os.path.exists(plag_path):\n",
    "            for level in os.listdir(plag_path):\n",
    "                level_path = os.path.join(plag_path, level)\n",
    "                if os.path.isdir(level_path):\n",
    "                    for author in os.listdir(level_path):\n",
    "                        author_path = os.path.join(level_path, author)\n",
    "                        if os.path.isdir(author_path):\n",
    "                            for file in os.listdir(author_path):\n",
    "                                if file.endswith(\".java\"):\n",
    "                                    data.append({\n",
    "                                        \"case_id\": case_id,\n",
    "                                        \"file_path\": os.path.join(author_path, file),\n",
    "                                        \"label\": \"plagiarized\",\n",
    "                                        \"plagiarism_level\": level\n",
    "                                    })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Cargar dataset\n",
    "print(\"Cargando dataset...\")\n",
    "base_dir = \"C:/Users/adria/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/AppAvanzadas/IR-Plag-Dataset/IR-Plag-Dataset\"\n",
    "df = load_dataset(base_dir)\n",
    "\n",
    "## 2. Extracción de Características (AST)\n",
    "def extract_enhanced_ast(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            code = f.read()\n",
    "        \n",
    "        tree = javalang.parse.parse(code)\n",
    "        tokens = []\n",
    "        \n",
    "        for path, node in tree:\n",
    "            node_type = type(node).__name__\n",
    "            tokens.append(node_type)\n",
    "            \n",
    "            # Añadir información específica de nodos importantes\n",
    "            if isinstance(node, javalang.tree.MethodDeclaration):\n",
    "                tokens.append(f\"METHOD_{node.name}\")\n",
    "                tokens.append(f\"PARAMS_{len(node.parameters)}\")\n",
    "                \n",
    "            if isinstance(node, (javalang.tree.IfStatement, \n",
    "                               javalang.tree.ForStatement,\n",
    "                               javalang.tree.WhileStatement)):\n",
    "                tokens.append(f\"CONTROL_{node_type.upper()}\")\n",
    "                \n",
    "            if isinstance(node, javalang.tree.Literal):\n",
    "                tokens.append(\"LITERAL_VALUE\")\n",
    "                \n",
    "        return ' '.join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"Extrayendo características AST...\")\n",
    "df['ast_tokens'] = df['file_path'].apply(extract_enhanced_ast)\n",
    "df = df.dropna(subset=['ast_tokens'])  # Eliminar archivos con errores de parsing\n",
    "\n",
    "## 3. División en Train/Test\n",
    "# Separamos manteniendo la proporción por case_id\n",
    "train_cases, test_cases = train_test_split(\n",
    "    df['case_id'].unique(), \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df['case_id'].isin(train_cases)].copy()\n",
    "test_df = df[df['case_id'].isin(test_cases)].copy()\n",
    "\n",
    "print(f\"\\nDistribución del dataset:\")\n",
    "print(f\"- Total: {len(df)} archivos\")\n",
    "print(f\"- Train: {len(train_df)} archivos ({len(train_cases)} casos)\")\n",
    "print(f\"- Test: {len(test_df)} archivos ({len(test_cases)} casos)\")\n",
    "\n",
    "## 4. Vectorización y Modelado\n",
    "# Entrenamos el vectorizador solo con los datos de entrenamiento\n",
    "# 4. Vectorización y Modelado (Versión Corregida)\n",
    "print(\"\\nEntrenando vectorizador...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=5000,\n",
    "    min_df=2\n",
    ")\n",
    "vectorizer.fit(train_df['ast_tokens'])\n",
    "\n",
    "# SOLUCIÓN 1: La forma más segura - usando reset_index() correctamente\n",
    "train_originals = train_df[train_df['label'] == 'original'].copy()\n",
    "train_originals = train_originals.reset_index() \n",
    "\n",
    "train_original_vectors = {\n",
    "    row['case_id']: vectorizer.transform([row['ast_tokens']])\n",
    "    for _, row in train_originals.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "# Preparamos los vectores para los originales de train\n",
    "train_originals = train_df[train_df['label'] == 'original'].set_index('case_id')\n",
    "train_original_vectors = {\n",
    "    case_id: vectorizer.transform([train_df.loc[idx, 'ast_tokens']])\n",
    "    for idx, case_id in train_originals.reset_index()[['case_id']].itertuples(index=True)\n",
    "}\n",
    "\n",
    "## 5. Evaluación del Modelo\n",
    "def evaluate_model(vectors, df, original_vectors, threshold=0.7):\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if row['label'] == 'original':\n",
    "            continue\n",
    "            \n",
    "        case_id = row['case_id']\n",
    "        if case_id not in original_vectors:\n",
    "            continue\n",
    "            \n",
    "        current_vec = vectors[idx]\n",
    "        original_vec = original_vectors[case_id]\n",
    "        \n",
    "        sim = cosine_similarity(current_vec, original_vec)[0][0]\n",
    "        predicted = 'plagiarized' if sim > threshold else 'non-plagiarized'\n",
    "        \n",
    "        results.append({\n",
    "            'case_id': case_id,\n",
    "            'file_path': row['file_path'],\n",
    "            'true_label': row['label'],\n",
    "            'predicted_label': predicted,\n",
    "            'similarity': sim,\n",
    "            'plagiarism_level': row.get('plagiarism_level', None)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nEvaluando en training set...\")\n",
    "train_vectors = vectorizer.transform(train_df['ast_tokens'])\n",
    "train_results = evaluate_model(train_vectors, train_df, train_original_vectors)\n",
    "\n",
    "print(\"\\nEvaluando en test set...\")\n",
    "test_vectors = vectorizer.transform(test_df['ast_tokens'])\n",
    "test_original_vectors = {\n",
    "    case_id: vectorizer.transform([test_df.loc[(test_df['case_id'] == case_id) & (test_df['label'] == 'original'), 'ast_tokens'].values[0]])\n",
    "    for case_id in test_df[test_df['label'] == 'original']['case_id'].unique()\n",
    "}\n",
    "test_results = evaluate_model(test_vectors, test_df, test_original_vectors)\n",
    "\n",
    "## 6. Visualización de Resultados\n",
    "def plot_metrics(results_df, title):\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(\n",
    "        results_df['true_label'] == 'plagiarized',\n",
    "        results_df['predicted_label'] == 'plagiarized',\n",
    "        normalize='true'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm, annot=True, fmt='.2%', cmap='Blues', \n",
    "                xticklabels=['Non-Plagiarized', 'Plagiarized'],\n",
    "                yticklabels=['Non-Plagiarized', 'Plagiarized'])\n",
    "    plt.title(f'Matriz de Confusión\\n{title}')\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.ylabel('Real')\n",
    "    \n",
    "    # Distribución de similitudes\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(\n",
    "        data=results_df,\n",
    "        x='similarity',\n",
    "        hue='true_label',\n",
    "        element='step',\n",
    "        stat='density',\n",
    "        common_norm=False,\n",
    "        bins=20\n",
    "    )\n",
    "    plt.axvline(x=0.7, color='r', linestyle='--', label='Umbral')\n",
    "    plt.title(f'Distribución de Similitudes\\n{title}')\n",
    "    plt.xlabel('Similitud Cosina')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nGenerando visualizaciones...\")\n",
    "plot_metrics(train_results, 'Training Set')\n",
    "plot_metrics(test_results, 'Test Set')\n",
    "\n",
    "## 7. Reporte de Métricas\n",
    "def print_metrics(results_df, set_name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Resultados para {set_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Reporte de clasificación\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(\n",
    "        results_df['true_label'] == 'plagiarized',\n",
    "        results_df['predicted_label'] == 'plagiarized',\n",
    "        target_names=['Non-Plagiarized', 'Plagiarized']\n",
    "    ))\n",
    "    \n",
    "    # Métricas por nivel de plagio (si existe)\n",
    "    if 'plagiarism_level' in results_df.columns:\n",
    "        print(\"\\nMétricas por Nivel de Plagio:\")\n",
    "        levels = sorted(results_df['plagiarism_level'].dropna().unique())\n",
    "        for level in levels:\n",
    "            level_df = results_df[results_df['plagiarism_level'] == level]\n",
    "            if len(level_df) > 0:\n",
    "                accuracy = np.mean(level_df['true_label'] == level_df['predicted_label'])\n",
    "                print(f\"- Nivel {level}: {accuracy:.2%} accuracy\")\n",
    "    \n",
    "    # Ejemplos de falsos negativos/positivos\n",
    "    print(\"\\nEjemplos destacados:\")\n",
    "    fp = results_df[(results_df['true_label'] == 'non-plagiarized') & \n",
    "                   (results_df['predicted_label'] == 'plagiarized')]\n",
    "    fn = results_df[(results_df['true_label'] == 'plagiarized') & \n",
    "                   (results_df['predicted_label'] == 'non-plagiarized')]\n",
    "    \n",
    "    print(f\"- Falsos positivos: {len(fp)} ejemplos\")\n",
    "    print(f\"- Falsos negativos: {len(fn)} ejemplos\")\n",
    "    \n",
    "    if len(fp) > 0:\n",
    "        example = fp.iloc[0]\n",
    "        print(f\"\\nEjemplo falso positivo (similitud={example['similarity']:.2f}):\")\n",
    "        print(f\"Archivo: {example['file_path']}\")\n",
    "    \n",
    "    if len(fn) > 0:\n",
    "        example = fn.iloc[0]\n",
    "        print(f\"\\nEjemplo falso negativo (similitud={example['similarity']:.2f}):\")\n",
    "        print(f\"Archivo: {example['file_path']}\")\n",
    "\n",
    "print_metrics(train_results, 'Training Set')\n",
    "print_metrics(test_results, 'Test Set')\n",
    "\n",
    "## 8. Optimización del Umbral\n",
    "print(\"\\nOptimizando umbral de decisión...\")\n",
    "precisions, recalls, thresholds = precision_recall_curve(\n",
    "    test_results['true_label'] == 'plagiarized',\n",
    "    test_results['similarity']\n",
    ")\n",
    "\n",
    "# Calcular F1-score para cada threshold\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, precisions[:-1], label='Precisión')\n",
    "plt.plot(thresholds, recalls[:-1], label='Recall')\n",
    "plt.plot(thresholds, f1_scores[:-1], label='F1-score')\n",
    "plt.axvline(x=best_threshold, color='r', linestyle='--', label=f'Mejor umbral ({best_threshold:.2f})')\n",
    "plt.xlabel('Umbral de Similitud')\n",
    "plt.ylabel('Puntuación')\n",
    "plt.title('Optimización del Umbral de Decisión')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nEl mejor umbral según F1-score es: {best_threshold:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
